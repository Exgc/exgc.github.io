{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "7w1U0l4AAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Xize Cheng（成曦泽）", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=7w1U0l4AAAAJ&citpid=7", "affiliation": "Zhejiang University", "organization": 1118375729466322660, "interests": ["Audio-Visual Processing", "Sound Separation", "Spoken Dialogue System"], "email_domain": "@zju.edu.cn", "homepage": "https://exgc.github.io/", "citedby": 300, "publications": {"7w1U0l4AAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Connecting multi-modal contrastive representations", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:9yKSN-GCB0IC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9748219438255061926", "cites_id": ["9748219438255061926"]}, "7w1U0l4AAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Chat-3d v2: Bridging 3d scene and large language models with object identifiers", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:ufrVoPGSRksC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9819100763177515104", "cites_id": ["9819100763177515104"]}, "7w1U0l4AAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mixspeech: Cross-modality self-learning with audio-visual stream mixup for visual speech translation and recognition", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:u5HHmVD_uO8C", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2782308253975293934", "cites_id": ["2782308253975293934"]}, "7w1U0l4AAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Wavtokenizer: an efficient acoustic discrete codec tokenizer for audio language modeling", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:M3ejUd6NZC8C", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11096367345508634509", "cites_id": ["11096367345508634509"]}, "7w1U0l4AAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "3drp-net: 3d relative position-aware network for 3d visual grounding", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:YsMSGLbcyi4C", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16908612795979015213", "cites_id": ["16908612795979015213"]}, "7w1U0l4AAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Opensr: Open-modality speech recognition via maintaining multi-modality alignment", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:UeHWp8X0CEIC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=145246247618274709", "cites_id": ["145246247618274709"]}, "7w1U0l4AAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Distilling coarse-to-fine semantic matching knowledge for weakly supervised 3d visual grounding", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:W7OEmFMy1HYC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14265841030039047524", "cites_id": ["14265841030039047524"]}, "7w1U0l4AAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Av-transpeech: Audio-visual robust speech-to-speech translation", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:u-x6o8ySG0sC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3031965472100444937", "cites_id": ["3031965472100444937"]}, "7w1U0l4AAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Chat-scene: Bridging 3d scene and large language models with object identifiers", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:QIV2ME_5wuYC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17772435643977512045", "cites_id": ["17772435643977512045"]}, "7w1U0l4AAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TAVT: Towards Transferable Audio-Visual Text Generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:IjCSPb-OGe4C", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8405869527932108496", "cites_id": ["8405869527932108496"]}, "7w1U0l4AAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring group video captioning with efficient relational approximation", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:eQOLeE2rZwMC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1242141084431509667", "cites_id": ["1242141084431509667"]}, "7w1U0l4AAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and Zero-shot Language Style Control With Decoupled Codec", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:UebtZRa9Y70C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=403976369840040732", "cites_id": ["403976369840040732"]}, "7w1U0l4AAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rethinking Missing Modality Learning from a Decoding Perspective", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:WF5omc3nYNoC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15571611745842547819", "cites_id": ["15571611745842547819"]}, "7w1U0l4AAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FreeBind: Free Lunch in Unified Multimodal Space via Knowledge Fusion"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:0EnyYjriUFMC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16449970934698418261", "cites_id": ["16449970934698418261"]}, "7w1U0l4AAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AudioLCM: Text-to-Audio Generation with Latent Consistency Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:hqOjcs7Dif8C", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14141182423302675181", "cites_id": ["14141182423302675181"]}, "7w1U0l4AAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Weakly-supervised spoken video grounding via semantic interaction learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:zYLM7Y9cAGgC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11081023641639229808", "cites_id": ["11081023641639229808"]}, "7w1U0l4AAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diffusion denoising process for perceptron bias in out-of-distribution detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:2osOgNQ5qMEC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10567998091823456008", "cites_id": ["10567998091823456008"]}, "7w1U0l4AAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Wavchat: A survey of spoken dialogue models", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:IWHjjKOFINEC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10592581576644801292", "cites_id": ["10592581576644801292"]}, "7w1U0l4AAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Omnibind: Large-scale omni multimodal representation via binding spaces", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:MXK_kJrjxJIC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15812878167712032072", "cites_id": ["15812878167712032072"]}, "7w1U0l4AAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Molecule-Space: Free Lunch in Unified Multimodal Space via Knowledge Fusion", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:Se3iqnhoufwC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15657380580640127305", "cites_id": ["15657380580640127305"]}, "7w1U0l4AAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:_FxGoFyzp5QC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17335056964216082744", "cites_id": ["17335056964216082744"]}, "7w1U0l4AAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Contrastive token-wise meta-learning for unseen performer visual temporal-aligned translation", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:Y0pCki6q_DkC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6919126084284083155", "cites_id": ["6919126084284083155"]}, "7w1U0l4AAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Synctalklip: Highly synchronized lip-readable speaker generation with multi-task learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:3fE2CSJIrl8C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9517869040528200200", "cites_id": ["9517869040528200200"]}, "7w1U0l4AAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ace: A generative cross-modal retrieval framework with coarse-to-fine semantic modeling", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:8k81kl-MbHgC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17963865233010865082", "cites_id": ["17963865233010865082"]}, "7w1U0l4AAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Semantic-conditioned dual adaptation for cross-domain query-based visual segmentation", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:Tyk-4Ss8FVUC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1235854903391084574", "cites_id": ["1235854903391084574"]}, "7w1U0l4AAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Boosting Speech Recognition Robustness to Modality-Distortion with Contrast-Augmented Prompts", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:kNdYIx-mwKoC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18339394012559630837", "cites_id": ["18339394012559630837"]}, "7w1U0l4AAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Text-to-Song: Towards Controllable Music Generation Incorporating Vocals and Accompaniment", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:9ZlFYXVOiuMC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1941313923866643833", "cites_id": ["1941313923866643833"]}, "7w1U0l4AAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AudioLCM: Efficient and High-Quality Text-to-Audio Generation with Minimal Inference Steps", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:Zph67rFs4hoC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5288166097147531298", "cites_id": ["5288166097147531298"]}, "7w1U0l4AAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VoiceTuner: Self-Supervised Pre-training and Efficient Fine-tuning For Voice Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:KlAtU1dfN6UC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2734032292025936296", "cites_id": ["2734032292025936296"]}, "7w1U0l4AAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rethinking the multimodal correlation of multimodal sequential learning via generalizable attentional results alignment", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:4TOpqqG69KYC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13964650549646815975", "cites_id": ["13964650549646815975"]}, "7w1U0l4AAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Landmark-guided Diffusion Model for High-fidelity and Temporally Coherent Talking Head Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:YOwf2qJgpHMC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13674371441331765710", "cites_id": ["13674371441331765710"]}, "7w1U0l4AAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Wav2sql: Direct generalizable speech-to-sql parsing", "pub_year": "2023"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:d1gkVwhDpl0C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8348701222387314867", "cites_id": ["8348701222387314867"]}, "7w1U0l4AAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "InstructSpeech: Following Speech Editing Instructions via Large Language Models"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:5nxA0vEk-isC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16502846156364932331", "cites_id": ["16502846156364932331"]}, "7w1U0l4AAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic Synchronization", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:Wp0gIr-vW9MC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16580481280231624909", "cites_id": ["16580481280231624909"]}, "7w1U0l4AAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Uni-Dubbing: Zero-Shot Speech Synthesis from Visual Articulation", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:_kc_bZDykSQC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12891700655446475971", "cites_id": ["12891700655446475971"]}, "7w1U0l4AAAAJ:mB3voiENLucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "OmniChat: Enhancing Spoken Dialogue Systems with Scalable Synthetic Data for Diverse Scenarios", "pub_year": "2025"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:mB3voiENLucC", "num_citations": 0}, "7w1U0l4AAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VoxpopuliTTS: a large-scale multilingual TTS corpus for zero-shot speech generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:HDshCWvjkbEC", "num_citations": 0}, "7w1U0l4AAAAJ:hC7cP41nSMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Wander Through the Multimodal Landscape: Efficient Transfer Learning via Low-rank Sequence Multimodal Adapter", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:hC7cP41nSMkC", "num_citations": 0}, "7w1U0l4AAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AudioVSR: Enhancing Video Speech Recognition with Audio Data", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:dhFuZR0502QC", "num_citations": 0}, "7w1U0l4AAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "OmniSep: Unified Omni-Modality Sound Separation with Query-Mixup", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:mVmsd5A6BfQC", "num_citations": 0}, "7w1U0l4AAAAJ:ULOm3_A8WrAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SegTalker: Segmentation-based Talking Face Generation with Mask-guided Local Editing", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:ULOm3_A8WrAC", "num_citations": 0}, "7w1U0l4AAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AVSET-10M: An Open Large-Scale Audio-Visual Dataset with High Correspondence", "pub_year": "2024"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:7PzlFSSx8tAC", "num_citations": 0}, "7w1U0l4AAAAJ:hFOr9nPyWt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and Zero-shot Language Style Control"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:hFOr9nPyWt4C", "num_citations": 0}, "7w1U0l4AAAAJ:-f6ydRqryjwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:-f6ydRqryjwC", "num_citations": 0}, "7w1U0l4AAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MindLoc: A Secure Brain-Based System for Object Localization"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:qUcmZB5y_30C", "num_citations": 0}, "7w1U0l4AAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Noise-Robust Audio-Visual Speech-Driven Body Language Synthesis"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:ZeXyd9-uunAC", "num_citations": 0}, "7w1U0l4AAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dynamic Switching Teacher: How to Generalize Temporal Action Detection Models"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:L8Ckcad2t8MC", "num_citations": 0}, "7w1U0l4AAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NaturalSigner: Diffusion Models are Natural Sign Language Generator"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:roLk4NBRz8UC", "num_citations": 0}, "7w1U0l4AAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Listen to Motion: Robustly Learning Correlated Audio-Visual Representations"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:LkGwnXOMwfcC", "num_citations": 0}, "7w1U0l4AAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Out-of-distribution Detection with Diffusion-based Neighborhood"}, "filled": false, "author_pub_id": "7w1U0l4AAAAJ:qjMakFHDy7sC", "num_citations": 0}}, "citedby5y": 300, "hindex": 10, "hindex5y": 10, "i10index": 11, "i10index5y": 11, "cites_per_year": {"2023": 46, "2024": 231, "2025": 21}, "updated": "2025-02-01 08:25:06.978205"}